\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[french,ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,urlcolor= blue,linkcolor= black}

\newcommand*{\itemb}{\item[$\bullet$]}
\newcommand*{\itemt}{\item[$\blacktriangleright$]}
\DeclareMathOperator{\degree}{degre}
\DeclareMathOperator{\taille}{taille}
\DeclareMathOperator{\voisin}{voisin}
\DeclareMathOperator{\voisins}{voisins}
\DeclareMathOperator{\degmax}{degmax}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\cover}{cover}
\DeclareMathOperator{\nonempty}{nonempty}
\DeclareMathOperator{\true}{true}
\DeclareMathOperator{\false}{false}
\DeclareMathOperator{\leaf}{leaf}
\DeclareMathOperator{\parent}{parent}
\DeclareMathOperator{\Color}{color}
\DeclareMathOperator{\degrepositif}{degrePositif}

\newcommand*{\dlor}[2]{\displaystyle{\underset{#1}{\overset{#2}{\bigvee}}}}
\newcommand*{\dland}[2]{\displaystyle{\underset{#1}{\overset{#2}{\bigwedge}}}}

\title{Projet Complexité et Algorithmique appliquée\\ Implémentation d'algorithmes pour résoudre le problème Vertex Cover}
\author{Thomas \bsc{Bellitto}\and Paul-Émile \bsc{Boutoille} \and Claire \bsc{Pennarun}}
\date{}

\begin{document}

\maketitle

\section*{Introduction}

Le projet consiste en l'implémentation d'algorithmes résolvant de manière approchée (en général) ou optimale (pour certaines classes de graphes) le problè-me Vertex-Cover.
Les algorithmes présentés ici renvoient une liste des sommets formant une couverture du graphe. Cette couverture n'est cependant pas forcément minimale.

Nous avons implémenté l'ensemble de ces algorithmes en langage C, car le groupe était plus à l'aise dans ce langage qu'en C++.

Nous avons développé une structure de graphes ainsi qu'une structure de liste que nous détaillerons dans la première partie de ce rapport, ainsi que les algorithmes de génération de graphes demandés.
Dans une deuxième partie, nous décrirons les algorithmes implémentés et donnerons une estimation de leur complexité et les résultats obtenus.
Enfin, nous présenterons une solution via une réduction au problème de satisfiabilité et l'utilisation du solveur \texttt{minisat}.

Notations : dans ce rapport, le graphe considéré sera généralement noté $G$. Sa taille (le nombre de ses sommets) sera notée $n$. Les ensembles de ses sommets et de ses arêtes seront respectivement notés $V(G)$ et $E(G)$, et son degré sera noté $\Delta (G)$. Sa taille sera égale à son nombre de sommets et sera notée $n = |V(G)|$.

Le code est disponible à \href{http://github.com/ClairePennarun/CAA_Vertex_Cover }{l'adresse suivante}.

\section{Graphes}

\subsection{Structures de données}

\subsubsection{Listes}

Au vu de différents algorithmes (et en prévision de la structure de graphe), nous avons choisi d'implémenter un module de liste.
Dans ce module, deux types ont été définis : le type 'List' (qui sera manipulé) et le type 'Elem' (représentant un élément : il sera caché à l'utilisateur).

Une liste contient ces champs :
\begin{itemize}
	\itemb Sa taille
	\itemb Un pointeur vers son premier élément (\texttt{NULL} si liste vide)
	\itemb Un pointeur vers son dernier élément (\texttt{NULL} si liste vide)
	\itemb Un pointeur vers l'élément courant (possiblement à \texttt{NULL} si l'on est sorti de la liste)
\end{itemize}
~~\\
Un élément contient ces champs :
\begin{itemize}
	\itemb Un pointeur vers l'élément suivant
	\itemb Un pointeur vers l'élément précédent
	\itemb Sa valeur (initialement un int)
\end{itemize}
\bigskip
Nous avons codé ensuite une collection de primitives classiques permettant la bonne manipulation de la liste (getVal, next, head, insertInHead, contain, isEmpty, isOutOfList...)

\subsubsection{Graphes}

Nous nous sommes tout de suite posé la question de la représentation du graphe en mémoire, et avons ainsi du faire un choix d'implémentation :
\begin{itemize}
	\itemb Représenter le graphe par une matrice d'adjacence de taille $n^2$ :
	\begin{itemize}
		\item Avantage : \texttt{sontVoisins(s1, s2)} serait de complexité $O(1)$
		\item Inconvénients : \texttt{getListeVoisins(s1)} serait de complexité $O(n)$, coûteux en mémoire
	\end{itemize}
\itemb Représenter le graphe par un tableau de sommets où chaque sommet contiendrait une liste de ses voisins :
	\begin{itemize}
		\item Avantages : la complexité de \texttt{getListeVoisins(s1)} serait $O(1)$
	\item Inconvénients : la complexité de \texttt{sontVoisins(s1, s2)} serait $O(\Delta(G))$
	\end{itemize}
\itemb Utiliser les deux représentations en même temps :
	\begin{itemize}
		\item Avantages : les complexité de \texttt{getListeVoisins(s1)} et de \texttt{sontVoisins(s1, s2)} seraient O(1)
		\item Inconvénients : redondance d'information en mémoire, cumul des coûts des deux structures dans la maintient du graphe
	\end{itemize}
\end{itemize}
~~\\
Partant de la constatation que la fonction \texttt{getListeVoisins} allait être utilisée (contrairement à \texttt{sontVoisins}) nous avons choisi la deuxième option.

Nous avons donc deux types : 'Graph' est manipulé et 'Vertex' est caché à l'utilisateur.

Un graphe contient :
\begin{itemize}
\itemb Son nombre de sommets
\itemb Son nombre d'arêtes
\itemb Un tableau contenant la liste de ses sommets
\itemb Un booléen indiquant si le graphe est orienté ou non
\end{itemize}

Un sommet, quand à lui, ne contient que la liste de ses voisins (liste étant implémentée grâce au module précédent).

Nous avons par la suite implémenté les primitives permettant de manipuler le graphe et y collecter des informations (getDegreGraph, getDegreVertex, getSize, cloneGraph, addEdge...)

\subsection{Génération aléatoire}

\subsubsection{Le module}

Il a fallu implémenter des sous-fonctions plusieurs fois utilisées, notamment pour conserver la propriété de Graphe connexe dans tout les algorithmes :
\BlankLine
\begin{itemize}
	\itemb \texttt{random()} : Retourne un double aléatoire inclus dans [0,1[.
	\itemb \texttt{randint(int a, int b)} : Retourne un entier aléatoire inclus dans [a, b[.
	\itemb \texttt{swap(int* t, int i1, int i2)} : Echange les cases d'indices i1 et i2 dans le tableau t.
	\itemb \texttt{randomEdge(Graph g, int i1, int i2, double proba)} : Connecte les sommets d'indices i1 et i2 dans le graphe g avec une probabilité de 'proba', et retourne un booléen indiquant si la connexion à été faite ou non.
	\itemb \texttt{makeConnected(Graph g, int i, int* tab, int iMin, int iMax, bool isConnected)} : Si 'isConnected' est à false (le sommet d'indice i est isolé), alors cela le connectera avec un sommet d'indice tab[k] (où k est un entier aléatoire inclus dans [iMin, iMax[).
	\itemb \texttt{getRandomVertice(int n)} : Retourne un tableau d'ordre aléatoire avec des entiers allant de $0$ à $n-1$. Les algorithmes de génération travailleront sur ce tableau d'indices (plutôt que directement sur les vrais indices), ce qui nous assurera qu'ils auront un impact "homogène" sur les sommets (le rôle de chaque sommet sera attribué de manière équiprobable).
\end{itemize}

\subsubsection{Génération de graphe quelconque}

\begin{algorithm}[H]
\caption{Algorithme de génération de graphe quelconque}
\Entree{Un nombre de sommet $n$ à générer et une probabilité $proba$ de connexion entre tout couple de sommet}
\Sortie{Un graphe connexe quelconque généré aléatoirement}
\BlankLine
G $\leftarrow$ graphe de taille n

ordreSommets $=$ getRandomVertices($n$)

création d'un booléen \texttt{estConnecté}

\Pour{$i$ de $0$ à $n-1$}{

estConnecté $=$ false

\Pour{$j$ de $i$ à $n-1$}{

estConnecté $=$ randomEdge(G, ordreSommets[$i$], ordreSommets[$j$], proba) OU estConnecté

}
makeConnected(G, ordreSommets[$i$], ordreSommets, $i$, $n$, estConnecté)

}

\Retour{G}

\end{algorithm}
\bigskip

Comme dit précédemment, l'algorithme travail sur un ordre aléatoire des sommets (et non pas sur les vrai indices). Pour des raisons de simplicité, nous considérerons dorénavant, dans nos explications, que les nombres manipulés représentent directement les indices des sommets.

La variable \texttt{estConnecté} sera mise à  jour pour qu'à la fin de la deuxième boucle \texttt{for} elle indique si le sommet courant (d'indice $i$) est connecté à un des sommets précédent (d'indice dans $j\in[0, i[$).

Nous saurons donc (par induction) qu'une seule composante connexe va croître au fur et à mesure et chaque nouveau sommet y sera connecté. Le graphe généré $G$ sera donc connexe.

\subsubsection{Génération d'arbre}

\begin{algorithm}[H]
\caption{Algorithme de génération d'arbre quelconque}
\Entree{Un nombre de sommet $n$ à générer}
\Sortie{Un arbre quelconque généré aléatoirement}
\BlankLine
G $\leftarrow$ graphe de taille n

ordreSommets $=$ getRandomVertices($n$)

\Pour{$i$ de $0$ à $n-1$}{

ajouterArête(G, ordreSommet[$i$], ordreSommet[randint($0$, $i$)]

}

\Retour{G}

\end{algorithm}
\bigskip

Nous connectons chaque sommet d'indice $i$ à un unique sommet d'indice $j\in[0, i[$ (ce sommet peut être vu comme le "père" de ce sommet et $j$ n'est pas une variable explicitement définit dans l'algorithme).

Grâce aux mêmes arguments que précédemment, nous savons que nous obtiendrons un graphe connexe. Si cette composante connexe qui croît est sans cycle, il faudrait y ajouter un sommet avec au moins deux arêtes pour en créer un.

Or nous n'ajoutons qu'une arête à chaque nouveau sommet, donc nous ne créons pas de cycle. Puisque la première composante connexe (une arête connectant les sommets d'indices $0$ et $1$) est sans cycle, nous pouvons prouver par induction que le graphe obtenu sera lui aussi sans cycle : c'est donc bien un arbre.

\subsubsection{Génération de graphe biparti}

\begin{algorithm}[H]
\caption{Algorithme de génération de graphe biparti}
\Entree{Un nombre de sommet $n$ à générer et une probabilité $proba$ de connexion entre tout couple de sommet}
\Sortie{Un graphe connexe biparti généré aléatoirement}
\BlankLine
G $\leftarrow$ graphe de taille n

ordreSommets $=$ getRandomVertices($n$)

création d'un booléen \texttt{estConnecté}

création d'un tableau extensible \texttt{part1} de taille $size1=0$

création d'un tableau extensible \texttt{part2} de taille $size2=0$

\bigskip
ajouter(part1, ordreSommet[$0$])

ajouter(part2, ordreSommet[$1$])

ajouterArête(G, ordreSommet[$0$], ordreSommet[$1$])

\Pour{$i$ de 2 à $n-1$}{

estConnecté $=$ false

\eSi{$random() < 0.5$}
{
\Pour{$j$ de $0$ à $size2$}{
estConnecté $=$ randomEdge(G, ordreSommets[$i$], part2[$j$], proba) OU estConnecté
}
makeConnected(G, ordreSommets[$i$], part2, $0$, size2, estConnecté)

ajouter(part1, ordreSommet[$i$])
}
{
\Pour{$j$ de $0$ à $size1$}{
estConnecté $=$ randomEdge(G, ordreSommets[$i$], part1[$j$], proba) OU estConnecté
}
makeConnected(G, ordreSommets[$i$], part1, $0$, size1, estConnecté)

ajouter(part2, ordreSommet[$i$])
}
}

\Retour{G}

\end{algorithm}
\bigskip

Les tableaux extensibles représentent les deux partitions de G. On les initialise arbitrairement avec le sommet d'indice $0$ dans la première partition et le sommet d'indice $1$ dans la seconde, puis on les relie. (on part ainsi avec une composante connexe et deux partitions non vide).

Ensuite, pour chaque nouveau sommet, on l'ajoutera aléatoirement dans la première ou dans la seconde partition (grâce au tirage \texttt{random < 0.5}). On utilisera la même méthode que précédemment pour s'assurer d'avoir des sommets connecté à la composante connexe déjà présente (\texttt{estConnecté} et \texttt{makeConnected}), tout en veillant à ne les connecter qu'à des sommets de la partition opposée.

\subsubsection{Génération de graphe à petite couverture}

\begin{algorithm}[H]
\caption{Algorithme de génération de graphe à couverture minimale de taille fixée}
\Entree{Un nombre de sommet $n$ à générer, une probabilité $proba$ de connexion entre tout couple de sommet et en entier $k$ représentant la taille de couverture souhaitée}
\Sortie{Un graphe connexe de couverture de taille k généré aléatoirement}
\BlankLine
G $\leftarrow$ graphe de taille n

ordreSommets $=$ getRandomVertices(n)

\Pour{$k_i$ de $0$ à $k$}{

ajouterArête(G, ordreSommets[$k_i$], ordreSommets[$k+k_i$])

\Pour{$k_j$ de $k_i+1$ à $k$}{

randomEdge(G, ordreSommets[$k_i$], ordreSommets[$k_j$], proba)

}
}

création d'un booléen \texttt{estConnecté}

\Pour{$g_i$ de $2k$ à $n-1$}{

estConnecté $=$ false

\Pour{$k_i$ de $0$ à $k$}{

estConnecté $=$ randomEdge(G, ordreSommets[$g_i$], ordreSommets[$k_i$], proba) OU estConnecté

}
makeConnected(G, ordreSommets[$g_i$], ordreSommets, $0$, $k$, estConnecté)

}

\Retour{G}

\end{algorithm}
\bigskip

Durant la première boucle, nous parcourons tout les sommets de la couverture (fixés arbitrairement comme les $k$ premiers) et nous effectuons deux opérations :
\begin{itemize}
\itemb Nous les connectons à un sommet qui leur sera exclusif (il ne sera relié qu'à eux). Le voisin exclusif du sommet de la couverture $k_i$ sera le sommet $k_i+k$. Cette opération nous permettra de rendre nécessaire chaque sommet de la couverture.
\itemb Nous connectons aléatoirement (toujours avec la probabilité \texttt{proba}) les sommets de la couverture entre eux.
\end{itemize}
\bigskip
La deuxième boucle (commençant donc après les sommets exclusifs : à $2\times k$) connectera chaque sommet à au moins un sommet de la couverture (en utilisant toujours \texttt{estConnecté} et \texttt{makeConnected}), ce qui nous permettra de nous assurer que le graphe obtenu est connexe.
\bigskip

Note : Cette méthode nécessite de réserver un sommet exclusifs à chaque sommet de la couverture, et donc ne fonctionne qu'avec des couvertures de taille $k\leqslant n/2$.

En fait nous générons un couplage de taille $k$ qui nous garanti qu'aucune couverture plus petite n'existe. Cependant nous avons conscience que, par cette méthode, notre algorithme ne pourra pas générer tout l'ensemble des graphes de couverture de taille $k$. De plus, il impose une borne max à la taille de la couverture (contrainte moins gênante puisqu'il est destiné à générer des graphes à petite couverture).

\section{Algorithmes réalisés}

\subsection{Algorithme glouton}

\subsubsection{Description}

L'algorithme glouton (\texttt{greedyAlg}) consiste à ajouter à chaque étape dans la couverture le sommet qui couvrira le plus d'arêtes non couvertes. Bien que non optimal, il a l'avantage d'être rapide. 

Le nombre d'arêtes couvertes par un sommet est égal à son degré, mais quand un sommet est ajouté à la couverture, il est important de ne plus tenir compte des arêtes adjacentes dans la suite. Pour connaître rapidement le nombre d'arêtes que l'on couvrirait avec chaque sommet, nous avons choisi de créer un tableau répertoriant le degré de chaque sommet du graphe, plus facile à tenir à jour que le graphe lui-même. 

L'algorithme s'arrête quand il n'est plus possible de couvrir une nouvelle arête. Le tableau des degrés ne contiendra alors plus de valeur positive, ce qui se détecte facilement, puisqu'on doit de toute façon chercher le sommet de plus haut degré à chaque itération.

On obtient l'algorithme suivant :

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un graphe défini par un tableau $\mathtt{voisin}$ de listes d'adjacence}
\Sortie{Une couverture d'arêtes, sous forme de liste de sommets}
\BlankLine

$n=\taille(G)$

$\degmax=1$

$\cover \leftarrow$ liste

création d'un tableau $\mathtt{degre}$ de taille $n$.

\Pour{$i$ de 0 à $n-1$}{

$\mathrm{\degree[i] = \taille(\voisin[i])}$
}

\Tq{$\degmax\neq 0$}{

$v=\argmax(\degree)$

$\degmax=\degree[v]$

\Si{$\degmax\neq 0$}{

$\mathrm{ajouter}(\cover, v)$ % ou "ajouter $v$ a cover" ?

$\mathrm{actualiser}(\degree, v)$
}
}
\Retour{$\cover$}
\caption{Algorithme glouton - greedyAlg}
 
\end{algorithm}

\vspace{0.35cm}
Si un sommet est ajouté à la couverture, on ne couvre plus d'arêtes en le couvrant une seconde fois. On peut donc passer sa valeur dans le tableau $\mathtt{degre}$ à 0. De plus, chaque sommet voisin couvre une arête de moins et on peut donc diminuer sa valeur de 1. Si on baisse de 1 la valeur d'un sommet qui a déjà été ajouté, on obtient des valeurs négatives, mais ce sont des sommets qui sont déjà dans la couverture, donc il n'y a pas de conséquence. Tester à chaque fois si le sommet appartient à la couverture ou non serait une perte de temps.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Le tableau $\mathtt{voisin}$, le tableau $\mathtt{degre}$ à mettre à jour et le sommet $v$ qu'on enlève du graphe}
\BlankLine
$\degree[v]=0$

\Pour{$i\in \voisin[v]$}{

décrémenter $\voisin[i]$ de 1
}
\caption{Actualiser}
 
\end{algorithm}

\subsubsection{Complexité}

\begin{itemize}
 \itemb La création du tableau $\mathtt{degre}$, incluant la boucle des lignes 5 et 6 se fait en $O(n)$
 \itemb On passera $c+1$ fois dans la boucle initiée à la ligne 7, où $c$ est la taille de la couverture renvoyée. À chaque fois :
\begin{itemize}
\itemt Déterminer le sommet de degré maximum (ligne 8) se fait en $O(n)$
\itemt La fonction \texttt{actualiser} tourne en $\deg(V)\leqslant n$.
\end{itemize}
\end{itemize}

Finalement, la complexité de l'algorithme glouton est $O(c\times n)$ (où $c$ est la taille de la couverture renvoyée).

Cependant, on peut remarquer que la phase de recherche du sommet de degré maximum pourrait se faire avec une complexité plus faible, car pour l'instant notre algorithme parcourt à chaque itération l'ensemble des sommets pour chercher celui de plus haut degré, et cela n'est pas efficace : à l'itération précédente, les seuls sommets qui ont changé de degré sont les voisins de celui que l'on a mis dans la couverture. Tenir à jour une liste des sommets triée en fonction de leur degré serait plus efficace : on déplacerait seulement les sommets ayant changé de degré à chaque itération.

\subsubsection{Résultats}

\paragraph{Taille de la couverture trouvée}

Nous avons comparé la taille de la couverture trouvée avec la taille de la couverture effective (sur des graphes générés avec \texttt{littleGen}) :
%%% A COMPLETER

\paragraph{Cohérence avec la complexité}
L'algorithme a été testé sur une série de 100 graphes, générés aléatoirement avec la fonction \texttt{generation}, et une probabilité d'apparition des arêtes de 0.5. 
Les tests ont été effectués sur une même machine.

\bigskip
\begin{tabular}{|c|c|c|c|c|c|c|c|}
	\hline 
	nb de sommets & 50 & 100 & 200 & 300 & 400 & 500 & 800  \\
	\hline
	temps (s) & 0.01 & 0.13 & 0.64 & 2.09 & 5.91 & 19.27 & 131.06 \\
	\hline
\end{tabular}

\bigskip

On voit que si on multiplie par deux la taille des graphes considérés, le temps de calcul de la couverture par l'algorithme $greedyAlg$ est multiplié par un facteur supérieur à 4.


Les temps d'exécution de notre algorithme sont donc moins bons que ceux prédits par la complexité estimée, et cela est sûrement dû à notre gestion du tableau des degrés, qui n'est pas optimale.

\subsection{Pour les arbres}

\subsubsection{Description}

L'algorithme optimal pour les arbres (\texttt{treeOptAlg}) fonctionne de la façon suivante : on commence par chercher une feuille (notée $u$), il faudra forcément couvrir l'arête qui relie la feuille à son parent (noté $v$). Deux options s'offrent alors : ajouter $u$ à la couverture ou $v$. Comme l'ensemble des arêtes couverte par la feuille est inclus dans l'ensemble des arêtes couvertes par son parent, il y a forcément une couverture optimale qui contient $v$. 

Une fois que le parent est ajouté à la couverture, on peut supprimer toutes les arêtes qu'il couvre et les sommets orphelins, puis itérer, la terminaison étant assurée par le fait que le graphe est un arbre. Comme pour l'algorithme précédent, nous avons choisi de travailler sur un tableau contenant les degrés de chaque sommet, plus facile à tenir à jour que le graphe lui-même. Les feuilles étant caractérisées par un degré égal à 1, elles sont faciles à détecter à partir de ce tableau. On obtient l'algorithme suivant :

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un arbre défini par un tableau $\mathtt{voisin}$ de listes d'adjacence}
\Sortie{Une couverture d'arêtes, sous forme de liste de sommets}
\BlankLine

$n=\taille(G)$

$\degree \leftarrow$ tableau de taille $n$.

$\cover \leftarrow$ liste

$\nonempty=\true$

\Pour{$i$ de 0 à $n-1$}{

$\mathrm{\degree[i] = \taille(\voisin[i])}$
}

\Tq{$\nonempty$}{

$v=\leaf(\degree)$

\eSi{$v=-1$}{$\nonempty=\false$}
{$w=\parent(v,\degree,\voisin)$

$\mathrm{ajouter}(\cover, w)$

$\mathrm{actualiser}(\degree, w)$}

}

\Retour{$\cover$}
\caption{Algorithme optimal pour les arbres - treeOptAlg}
 
\end{algorithm}

Où la fonction \texttt{leaf} renvoie le premier sommet dont le degré est 1 (c'est-à-dire la première feuille), et -1 s'il n'y en a pas.

\subsubsection{Complexité}

\begin{itemize}
 \itemb La création du tableau $\mathtt{degre}$, incluant la boucle des lignes 5 et 6 se fait en $O(n)$
 \itemb On passera $c+1$ fois dans la boucle initiée à la ligne 7, où $c$ est la taille de la couverture renvoyée. À chaque fois :
\begin{itemize}
\itemt La fonction \texttt{leaf} tourne en $O(n)$.
\itemt La fonction \texttt{actualiser} tourne en $O(\deg(v))$, et $\deg (v)\leqslant n$.
\end{itemize}
\end{itemize}

Finalement, la complexité finale de l'algorithme glouton est $O(c\times n)$, où $c$ est la taille de la couverture renvoyée, qui est une grandeur linéaire en $n$. La complexité estimée de l'algorithme est donc $O(n^2)$. 

\subsubsection{Résultats}

Les tests ont été effectués sur une même machine. Ils consistent en l'exécution de l'algorithme \texttt{treeOptAlg} consécutivement sur 100 graphes de taille $n$. Le temps est donné en secondes.
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 200 & 500 & 1000 & 1500 & 2000 & 5000 & 10000 & 15000 & 20000 & 50000 \\
	\hline
	tps & 0.01 & 0.06 & 0.22 & 0.41 & 0.77 & 4.38 & 16.92 & 37 & 65 & 442 \\
	\hline
\end{tabular}
\end{center}

On peut voir que quand la taille de l'entrée (le nombre de sommets) double, le temps de calcul est multiplié par un facteur proche de 4 :

$t(2000)/t(1000) = 3.5$, $t(10000)/t(5000) = 3.86$, $t(20000)/t(10000) = 3.84$.

Les temps d'exécution de notre algorithme sont donc en accord avec la complexité estimée.

\subsection{Pour les graphes bipartis}

\subsubsection{Description}

\begin{algorithm}[H]
\caption{Algorithme de calcul de bi-partition}
\Entree{Un graphe G biparti connexe}
\Sortie{Deux tableaux contenant les indices des sommets de chaque partition}
\BlankLine
n $\leftarrow$ taille(G)

création d'un tableau extensible \texttt{part1} de taille $size1=0$

création d'un tableau extensible \texttt{part2} de taille $size2=0$

aTester $\leftarrow$ liste

partitionPrévue $\leftarrow$ liste

voisins $\leftarrow$ liste

création d'un tableau de booléens \texttt{estVisité} de taille $n$ avec toute ses valeurs initialisée à false

\bigskip
ajouterEnQueue(aTester, $0$)

ajouterEnQueue(partitionPrévue, $1$)

création des entiers \texttt{sommetCourant}, \texttt{partitionCourante}, \texttt{voisinCourant}

\Tq{non(estVide(aTester))}
{
	sommetCourant = valeurEnTete(aTester)
	
	partitionCourante = valeurEnTete(partitionPrévue)
	
	supprimerEnTete(aTester)
	
	supprimerEnTete(partitionPrévue)
	
	voisins = getListeVoisins(G, sommetCourant)
	
	\Tq{non(outOfList(voisins))}
	{
		voisinCourant = getValeur(voisins)
		
		\Si{non(estVisité[voisinCourant])}
		{
			estVisité[voisinCourant] = true
			
			ajouterEnQueue(aTester, voisinCourant)

			ajouterEnQueue(partitionPrévue, 1-partitionCourante)
		}		
		
		next(voisins)
	}
	
	\eSi{partitionCourante = 1}
	{
		ajouter(part1, sommetCourant)
	}
	{
		ajouter(part2, sommetCourant)
	}
}

ajouter(part1, ordreSommet[$0$])

ajouter(part2, ordreSommet[$1$])

\Retour{[part1, part2]}

\end{algorithm}
\bigskip

Cette algorithme calcul la bi-partition d'un graphe biparti connexe.

Il effectue tout simplement un parcours en largeur en se rappelant quels sommets il n'a pas encore "rangés" et quels sommets il a déjà "visité".

Le premier sommet ($0$) est fixé arbitrairement dans la partition 1, puis chaque voisin d'un sommet a tester sera dans sa partition opposée (1-partitionCourante).


\bigskip
\bigskip
\begin{algorithm}[H]
\caption{Algorithme de construction du graphe orienté H}
\Entree{Un graphe G biparti connexe et ses deux partition part1 et part2 de taille respective size1 et size2 (tableaux d'entiers représentant les indices)}
\Sortie{Un graphe orienté H}
\BlankLine
n = taille(G)

s = n

t = n+1

size = n+2

H $\leftarrow$ graphe orienté de taille \texttt{size}

création des entiers \texttt{sommetCourant}, \texttt{voisinCourant}

\Pour{$i$ de $0$ à $size1$}{
	sommetCourant = part1[i]
	
	ajouterArêteOrientée(H, s, sommetCourant)
	
	voisins = getListeVoisins(G, sommetCourant)
	
	\Tq{non(outOfList(voisins))}
	{
		voisinCourant = getValeur(voisins)
		
		ajouterArêteOrientée(sommetCourant, voisinCourant)	
		
		next(voisins)
	}
}

\Pour{$i$ de $0$ à $size2$}{
	ajouterArêteOrientée(H, part2[i], t)
}

\Retour{H}

\end{algorithm}
\bigskip

Si on appel X et Y les deux partitions de G, alors l'algorithme effectue le travail suivant :
\begin{itemize}
\itemb Création du graphe orienté H de taille n+2 (deux nouveaux sommets : s et t)
\itemb On relie s vers tout les sommets de X
\itemb On ajoute toute les arêtes de G orientée de X vers Y
\itemb On relie tout les sommets de Y vers t
\end{itemize}

Ce graphe est nécessaire pour l'algorithme de couvertures optimal pour les graphes biparti. La prochaine étape est d'y appliquer l'algorithme de Ford-Fulkerson pour trouver un flux optimal allant de s vers t (toute les arêtes ayant une capacité de 1).


\bigskip
\bigskip
\begin{algorithm}[H]
\caption{Algorithme de Ford-Fulkerson}
\Entree{Le graphe orienté H et les deux partition part1 et part2 de G de taille respective size1 et size2 (tableaux d'entiers représentant les indices)}
\Sortie{Une couverture d'arêtes minimale \texttt{cover} sous forme de liste de sommets}
\BlankLine
n = taille(H)

s = n-2

t = n-1

création d'un tableau d'entiers \texttt{pères} de taille $n$

création d'un tableau d'entiers \texttt{couleurs} de taille $n$

création d'une matrice d'entiers \texttt{flux} de taille $n\times n$ avec toute les valeurs initialisée à 0

enfants $\leftarrow$ liste

parents $\leftarrow$ liste

F $\leftarrow$ liste

insérerEnTête(F, s)

création des entiers $u$, $v$, $w$

\Tq{non(estVide(F))}
{
	vider(F)
	
	insérerEnTête(F, s)
	
	\Pour{$i$ de $0$ à $n$}{
		couleurs[i] = 0
	}
	couleurs[s] = 1
	
	\Tq{couleurs[t]$=0$ ET non(estVide(F))}
	{
		v = valeurEnTête(F);
		supprimerEnTête(F);
	
		enfants = getListeSuivants(G, sommetCourant)
		
		\Tq{non(outOfList(enfants))}
		{
			w = getValeur(voisins)
			
			\Si{couleurs[w]$=0$ ET flux[v][w] = 0}
			{
				couleurs[w] = 1
				
				pères[w] = v
				
				insérerEnTête(F, w)
			}
			next(enfants)
		}

		parents = getListePrécédents(G, sommetCourant)
		
		\Tq{non(outOfList(parents))}
		{
			u = getValeur(parents)
			
			\Si{couleurs[u]$=0$ ET flux[u][v] = 1}
			{
				couleurs[u] = 1
				
				pères[u] = v
				
				insérerEnTête(F, u)
			}
			next(parents)
		}
		
		couleurs[v] = 2
	}
	
	v = t
	
	u = pères[v]
	\Tq{$u\neq v$}
	{	
		flux[u][v] = (1-flux[u][v])
		
		v = u
		
		u = pères[v]
	}
	flux[u][v] = (1-flux[u][v])
}

cover  $\leftarrow$ liste

\Pour{$i$ de $0$ à $size1$}{
	\Si{couleurs[part1[i]] = 0}
	{
		insérerEnTête(cover, part1[i]
	}
}
\Pour{$i$ de $0$ à $size2$}{
	\Si{couleurs[part2[i]] = 2}
	{
		insérerEnTête(cover, part2[i]
	}
}

\Retour{cover}

\end{algorithm}
\bigskip

Le tableau de couleur utilisé représente les couleurs de l'algorithme (0 pour blanc, 1 pour gris et 2 pour noir).

Chaque itération dans la boucle while principale fera trouver un chemin allant de s vers t, passant par un sommet de part1 et un sommet de part2.

On remarquera que l'ont pourra passer par des flux déjà à 1 mais seulement en allant d'un fils vers son père (cela correspond a trouver un chemin valide dans le graphe résiduel) ce qui permettra d'optimiser le flux.

Finalement, on ajoute dans la couverture tout les sommets dans la première partition coloriés en blanc et tout les sommets de la deuxième partition coloriés en noir.

\subsubsection{Complexité}

L'algorithme de calcul de la bipartition visitera une fois chaque sommet et lui trouvera directement sa partition. Sa complexité est donc linéaire ($O(|V(G)|)$).

La construction du graphe orientée sera également rapide. Il faudra recopier chaque sommet et orienter chaque arête, ce qui se traduira par un coût de ($O(|V(E)|+ |V(G)|)$).

L'algorithme de Ford-Fulkerson a quand a lui une très bonne complexité de ($O(|V(E)|)$) puisque toute les capacité d'arêtes sont à fixée à 1.

Nous pouvons donc en déduire que la complexité de l'algorithme de calcul de couverture minimale pour un graphe biparti, qui cumule ces trois algorithmes, est linéaire en la taille du graphe ($O(|V(E)|+ |V(G)|)$).

\subsubsection{Résultats}

Nous avons effectué des tests sur 100 graphes bipartis de taille $n$ générés aléatoirement avec \texttt{bipartiteGen} et une probabilité de 0.5. Les tests ont été effectués sur une même machine, et les temps sont donnés en secondes.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
	\hline 
	n & 200 & 300 & 400 & 500 & 800 & 1000 & 1500 \\
	\hline
	temps & 0.5 & 1.22 & 2.30 & 4.18 & 14.07 & 27.35 & 104 \\
	\hline
\end{tabular}
\end{center}

On voit que les résultats sont proches de ceux attendus : quand la taille de l'instance double, le temps d'exécution est multiplié par un facteur 6.6. Quand la taille de l'instance est multipliée par 5, le temps d'exécution est multiplié par un facteur compris entre 50 et 85. Cela correspond bien à la complexité estimée.

\subsection{Algorithme 2-approché avec arbre couvrant}

\subsubsection{Description}

L'algorithme se base sur un parcours en profondeur du graphe $G$. Le parcours en profondeur (DFS) crée un arbre couvrant du graphe. Notons que si deux sommets sont liés par une arête, le premier des deux à être visité ne sera pas une feuille de l'arbre puisqu'il a au moins un fils qui n'a pas encore été visité. Par contraposée, il ne peut pas y avoir d'arêtes entre deux feuilles de l'arbre induit par le DFS et l'ensemble des sommets de cet arbre qui ne sont pas des feuilles est donc une couverture du graphe. 

Partitionnons maintenant notre couverture en l'ensemble des nœuds de l'arbre de profondeur paire et ceux de profondeur impaire et intéressons nous à l'ensemble $E$ de plus grand cardinal. La taille de notre couverture est donc majorée par $2|E|$. En reliant chaque sommet de $E$ à son fils, on crée un ensemble d'arêtes indépendantes : en effet, notre couverture ne comportant pas de feuilles, chacun de ses sommets a un fils, et le profondeur du fils étant de parité différente de celle du père, le fils n'appartient pas à $E$. Ainsi, $|E|$ est un minorant de la taille d'une couverture de $G$. Notre algorithme est donc 2-approché.

\bigskip
Nous avons implémenté cet algorithme de deux manières différentes : la première version (algorithme \texttt{spanningTreeAlgRec}) en nous basant sur un algorithme récursif simple de parcours en profondeur, la deuxième version (algorithme \texttt{spanningTreeAlg}) en dérécursifiant le parcours en utilisant une liste doublement chaînée comme pile.

Chaque sommet de $G$ est \og coloré\fg quand il est visité par le parcours. Un tableau $\Color$ de taille $n$ est créé au début de l'algorithme pour nous permettre de stocker ces "couleurs" : 

\begin{itemize}
\item dans le premier algorithme : $\Color[i] = 0$ si le sommet $i$ n'a pas encore été visité, $\Color[i] = 1$ sinon.
\item dans le second algorithme : $\Color[i] = 0$ si le sommet $i$ n'a pas encore été visité, $\Color[i] = 1$ si le sommet est a été découvert (il est voisin d'un sommet visité), et $\Color[i] = 2$ si le sommet a été visité.
\end{itemize}



Pour savoir si un sommet $v$ est une feuille ou non, nous utilisons un booléen $\mathrm{isInCover}$ qui vaut $\false$ au début de la visite de $v$. Quand on rencontre pour la première fois un de ses voisins non déjà visité, le sommet $v$ est ajouté dans la couverture du graphe et la valeur de $\mathrm{isInCover}$ est mise à $\true$.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{le graphe $g$}
\Sortie{Une couverture d'arêtes, sous forme de liste de sommets $cover$}
\BlankLine
$n = \taille(G)$

$t \leftarrow$ tableau de taille $n$

$\cover \leftarrow$ liste

\Pour{$i\in V(G)$}
{$t[i] = 0$}

parcours\_profondeur($G, 0, \cover, t$)

\Retour{cover}
\caption{Algorithme avec arbre couvrant (récursif) - spanningTreeAlgRec}
 
\end{algorithm}

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{le graphe $G$, le sommet $v$ sur lequel on fait le parcours, la couverture $cover$ de sommets actuelle, le tableau de couleurs $t$}
\BlankLine

\Si{$t[v] = 1$}{
Fin du programme
}

estDansCover = False

$t[v] = 1$

\Pour{$i\in \voisin[v]$}{
\Si{$t[i] = 0$ et estDansCover = False}{
	ajout de $v$ à $\cover$
	
	estDansCover = True
	}	
parcours\_profondeur($G$, $i$, $\cover$, $t$)
}
\caption{parcours\_profondeur - dfs}
 
\end{algorithm}

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{le graphe $G$}
\BlankLine

$\cover \leftarrow$ liste % a voir si externe

pile $\leftarrow$ liste % a voir si externe

\Pour{$i \in V(G)$}{
	$\Color[i] = 0$;
	$\parent[i] = -1$;
}

$u$ $\leftarrow$ racine du graphe

$\Color[u] = 1$;

ajout de $u$ à pile

\Tq{pile $\neq$ []}{
	estDansCover = False
	
	$u \leftarrow$ tête de $pile$
	
	\Si{$\Color[u] \neq 2$}{
		$\Color[u] = 2$
	
		\Pour{$v \in voisin[u]$}{
			\Si{$\Color[v] \neq 2$}{
			$\Color[v] = 1$
			
			$\parent[v] = u$
			
			empiler $v$ dans pile
			
				\Si{estDansCover = False}{
				ajouter $u$ dans $\cover$
				
				estDansCover = True
				}
			}
		}
	}
}
\Retour{$\cover$}

\caption{Algorithme avec arbre couvrant (itératif) - spanningTreeAlg}
 
\end{algorithm}

\subsubsection{Complexité}

L'algorithme présenté demande un préprocessing faisable en temps linéaire (initialiser $t$ ou $\Color$), puis une opération sur les voisins de chaque sommet, qui requiert donc un temps en $O(|E|)$. La complexité temporelle de l'algorithme est donc $O(|E|)$, ce qui revient à $O(n^2)$ dans le cas général, et à $O(n)$ si le graphe considéré est un arbre.

\subsubsection{Résultats}

\paragraph{Taille de la couverture trouvée}

Nous avons comparé la taille $l$ de la couverture trouvée avec la taille $k$ de la couverture effective (sur des graphes générés avec \texttt{littleGen}) :
%%% A COMPLETER
\begin{itemize}
\item avec l'algorithme itératif :
\item avec l'algorithme récursif : l'algorithme nous retourne des couvertures de taille $l$ avec $l \leq 2*k$, il est bien 2-approché.
\end{itemize}

\paragraph{Comparaison des deux algorithmes}

Les deux versions (itérative et récur-sive) ont été exécutées sur un ensemble de 100 graphes de $n$ sommets (générés aléatoi-rement avec la fonction \texttt{generation} et une probabilité de 0.5), sur une même machine.
Les temps sont donnés en secondes.

Pour l'algorithme itératif :
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 100 & 200 & 300 & 500 & 800 & 1000 & 1500 & 2000 & 2500 \\
	\hline
	temps & 0.03 & 0.18 & 0.24 & 1.08 & 3.46 & 5.79 & 13.46 & 24.1 & 37.84 \\
	\hline
\end{tabular}
\end{center}

Pour l'algorithme récursif :
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 100 & 200 & 300 & 500 & 800 & 1000 & 1500 & 2000 & 2500 \\
	\hline
	temps & 0.02 & 0.09 & 0.18 & 0.48 & 1.72 & 3 & 7.07 & 13.23 & 19.68\\
	\hline
\end{tabular}
\end{center}

On voit que l'algorithme récursif va environ deux fois plus vite que sa version itérative.

Cependant, les temps d'exécution des deux algorithmes semblent correspondre à une même complexité : 
\begin{itemize}
\item pour l'algorithme itératif : quand la taille de l'instance double, le temps d'exécution est multiplié par un facteur situé entre 4 et 6, et quand la taille de l'instance est multipliée par 5, le temps d'exécution est multiplié par un facteur proche de 32.
\item pour l'algorithme récursif : quand la taille de l'instance est doublée, le temps d'exécution est multiplié par un facteur proche de 5, et quand la taille de l'instance est multipliée par 5, le temps d'exécution est multiplié par un facteur proche de 33 (par exemple, entre $n = 200$ et $n = 1000$).
\end{itemize}

\paragraph{Comparaison des temps sur des graphes généraux et des arbres}

Nous avons comparé les temps d'exécution de l'algorithme récursif sur 100 graphes de taille $n$ générés aléatoirement avec \texttt{treeGen} (les tests ont été faits sur la même machine que les deux précédents) :
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 1000 & 2000 & 3000 & 4000 & 5000 & 8000 & 10000 & 20000 & 50000 & 100000 \\
	\hline
	temps & 0.03 & 0.06 & 0.09 & 0.12 & 0.18 & 0.26 & 0.29 & 0.69 & 1.77 & 4.49\\
	\hline
\end{tabular}
\end{center}

On voit que les résultats sont cohérents avec la complexité estimée : les graphes considérés ne sont que des arbres, ce qui permet à l'algorithme d'aller d'une part beaucoup plus vite (il traite 100 arbres de 100000 sommets en moins de 5 secondes, alors qu'il ne traite que 100 graphes généraux de moins de 1500 sommets dans le même temps), et d'autre part d'avoir un temps d'exécution à peine plus que linéaire en la taille du graphe.


\subsection{Algorithme 2-approché par élimination d'arêtes}

\subsubsection{Description}

L'idée de l'algorithme par suppression d'arêtes (\texttt{edgesDeletionAlg}) est de choisir une arête du graphe, d'ajouter ses deux extrémités à la couverture et des les supprimer du graphe (ainsi que toutes les arêtes adjacentes), et d'itérer jusqu'à ce que le graphe n'ait plus d'arêtes. Ainsi, les arêtes tirées à chaque itération forment un ensemble d'arêtes indépendantes, et la taille de la couverture obtenue sera égale à deux fois la taille de cet ensemble. On remarque alors que la taille d'un ensemble d'arêtes indépendantes est un minorant de la taille d'une couverture du graphe puisqu'il faut un sommet différent pour couvrir chacune des arêtes de l'ensemble. L'algorithme décrit est donc 2-approché.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un graphe $G$ défini par un tableau $\mathtt{voisin}$ de listes d'adjacence}
\Sortie{Une couverture d'arêtes, sous forme de liste de sommets}
\BlankLine

$n=\taille(G)$

$v_1=\degrepositif(G,0)$

\Si{$v_1=0$}{\Retour{$\cover$}}

$\deg_1=\deg(v_1)$

\Tq{$\deg_1>0$}{

$\voisins=\voisin(v_1)$

$v_2$ est le premier élément de $\voisins$

$\mathrm{ajouter}(\cover,v_1)$

$\mathrm{ajouter}(\cover,v_2)$

$\mathrm{suppressionAretes}(G,v_1)$

$\mathrm{suppressionAretes}(G,v_2)$

$v_1=\degrepositif(G,v_1)$

\Si{$v_1=0$}{\Retour{$\cover$}}

$\deg_1=\deg(v_1)$

}


\Retour{$\cover$}
\caption{Algorithme par élimination d'arêtes - edgesDeletionAlg}
 
\end{algorithm}

La fonction \texttt{degrePositif} prend en argument un graphe $G$ et un indice $i$ et renvoie le premier sommet de $G$ de degré positif et d'indice supérieur à $i$, ou -1 s'il n'y en a pas. Si la dernière fois que la fonction a été appelée, le premier sommet de degré positif avait comme indice $i$, il est en effet inutile de chercher un sommet de degré positif avant l'indice $i$ puisque l'algorithme ne peut à aucun moment augmenter le degré d'un sommet.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un graphe $G$ défini par un tableau $\mathtt{voisin}$ de listes d'adjacence, un indice $i$}
\Sortie{Le premier sommet de $G$ de degré positif et d'indice supérieur à $i$}
\BlankLine

\Pour{$j$ de $i$ à $\taille(G)-1$}{

\Si{$\voisin(j)\neq [\quad]$}{\Retour{$j$}
}
}
\Retour {-1}


\caption{degrePositif}
 
\end{algorithm}

La fonction \texttt{suppressionAretes} prend en entrée un graphe $G$ et un sommet $v$ et supprime de $G$ toutes les arêtes adjacentes à $v$.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un graphe $G$ défini par un tableau $\mathtt{voisin}$ de listes d'adjacence, un sommet $v$}
\BlankLine

\Pour{$u\in\voisin(v)$}{

$\mathrm{supprimer}(v,\voisin(u))$
}

$\voisin(v)\leftarrow [\quad]$

\caption{suppressionAretes}
 
\end{algorithm}

\subsubsection{Complexité}

Le nombre d'appels de la fonction \texttt{degrePositif} importe en fait assez peu : le fait que la fonction garde en mémoire l'indice du dernier sommet trouvé assure que la somme des temps d'exécution sera en $O(n)$. La complexité de l'algorithme viendra donc des appels de la fonction \texttt{suppressionAretes}, aux lignes 11 et 12. On sait que la fonction \texttt{suppressionAretes} supprimera au maximum $|E(G)|$ arêtes et que chaque suppression d'arête demandera de chercher un élément dans une liste de voisins d'un sommet, de taille majorée par $\Delta(G)$.

Ainsi, l'algorithme tourne en $O(|E|\times \Delta(G))$ où $\Delta(G)$ est le degré maximum du graphe, ce qui correspond à $O(n^3)$ au pire pour des graphes généraux, et à $O(n^2)$ au pire pour des arbres.

\subsubsection{Résultats}

\paragraph{Taille de la couverture trouvée}

Nous avons comparé la taille de la couverture trouvée avec la taille de la couverture effective (sur des graphes générés avec \texttt{littleGen}) :
%%% A COMPLETER

\paragraph{Tests}
Nous avons testé l'algorithme par élimination d'arêtes sur des séries de 100 graphes de taille $n$ générés aléatoirement avec \texttt{generation} et une probabilité de 0.5. Les tests ont été faits sur la même machine, et les temps sont donnés en secondes.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 100 & 200 & 300 & 400 & 500 & 600 & 700 & 800 & 1000 \\
	\hline
	temps & 0.03 & 0.32 & 1.06 & 2.53 & 4.95 & 8.56 & 15.03 & 27.09 & 64.76 \\
	\hline
\end{tabular}
\end{center}

On voit que quand la taille de l'instance est doublée, le temps d'exécution est multiplié par un facteur 8, et quand elle est multipliée par 3, le temps d'exécution est multiplié par un facteur 26.75.
Ces temps montrent bien que notre algorithme se comporte conformément à la complexité estimée.

\bigskip
Nous avons ensuite testé l'algorithme sur des séries de 100 arbres générés aléatoirement avec \texttt{treeGeneration} ; ces graphes ayant moins d'arêtes, nous nous attendons à pouvoir traiter des graphes de taille plus grande.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
	\hline 
	n & 500 & 1000 & 2000 & 5000 & 10000 & 20000 & 50000 & 100000 & 200000\\
	\hline
	temps & 0.02 & 0.04 & 0.07 & 0.11 & 0.23 & 0.76 & 2.58 & 6.21 & 13.91\\
	\hline
\end{tabular}
\end{center}

Effectivement, on voit d'une part que les arbres pouvant être traités par série de 100 en moins de 10 secondes ont une taille supérieure à 100000 sommets, tandis que sur des graphes généraux, seuls des graphes de taille légèrement supérieure à 700 sommets peuvent être traités dans le même temps. D'autre part, on voit que quand la taille des graphes est doublée, le temps d'exécution est multiplié par un facteur proche de 2 également, ce qui est en accord avec une complexité linéaire de l'algorithme pour des arbres.


\subsection{Algorithme paramétrique pour faible couverture}

\subsubsection{Description}

L'algorithme paramétrique (\texttt{littleCover}) permet de tester si le graphe comporte une couverture par sommets d'une taille $k$ donnée, et de la retourner le cas échéant.

\bigskip
Pour cela, nous commençons par effectuer une kernelisation du problème. Soit $U = \{ v \in V(G) \mid deg(v) > k\}$. On sait que $G$ admet une $k$-couverture si et seulement si $G \smallsetminus U$ admet une $(k - |U|)$-couverture.

On recherche donc le nombre $l = |U|$ de sommets de degré strictement supérieur à $k$. 
Si $l > k$, alors on ne pourra pas trouver de couverture de taille $k$ et on peut arrêter l'algorithme.
Si le graphe comprend plus de $k\times(k-l)$ arêtes, on peut également arrêter l'algorithme.

Si ces deux tests n'entraînent pas l'arrêt de l'algorithme, on \og réduit\fg le graphe $G$ à $G \smallsetminus U \smallsetminus \{v \in V \mid deg(v) = 0\}$, en cherchant une couverture plus petite, de taille $k-l$.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un graphe $G$, la taille $k$ de la couverture recherchée}
\BlankLine

$l = 0$ \tcp*{nombre de sommets de degré trop grand}

$m = 0$ \tcp*{nombre de sommets isolés}

$n = \taille(G)$

gdDegres \tcp*{tableau de sommets de degré trop grand}

degreNul \tcp*{tableau de sommets de degré nul}

\Pour{$v \in V(G)$}{
	\Si{$\deg(v) > k$}{
		gdDegres[$l$] = $v$
		
		$l = l+1$
	}
	\Si{$\deg(v) = 0$}{
		degreNul[$m$] = $v$
		
		$m = m+1$
	}
}

$k' = k - l$

\Si{$k'\leqslant 0$}{
	\Retour{NULL}
}
\Si{$l>0$}{
	\Pour{$i$ de 0 à $l-1$}{
		$u$ = grdDegres[$i$]
		
		suppressionAretes($G$,$u$)
		
		suppressionSommet($G$,$u$)
	}
}
\Si{$m>0$}{
	\Pour{$i$ de 0 à $m-1$}{
		$u$ = degreNul[$i$]
		
		suppressionSommet($G$,$u$)
	}
}

\Si{nombreAretes($G$) $> k\times k'$}{
	\Retour {NULL}
}
$\cover$ = petiteCouvertureAlg($G$,$k'$,$n-l$)

\Pour{$i$ de 0 à $l-1$}{
	ajouter grdDegres[$i$] à $\cover$
}

\Retour{$\cover$}

\caption{recherchePetiteCouverture - littleCover}
\end{algorithm}

L'algorithme principal est ensuite appliqué. Il consiste en une série de tests qui permettent soit d'écarter rapidement la possibilité de l'existence d'une couverture de taille $k$, soit de renvoyer directement une telle couverture. 

Les tests sont : 
\begin{itemize}
\item si $k$ est supérieur à la taille du graphe, alors tous les sommets sont dans la couverture.
\item si $k$ est négatif, alors le graphe n'a pas de couverture de taille $k$.
\item si le graphe comporte plus de $k\times(n-1)$ arêtes, alors il n'a pas de couverture de taille $k$.
\end{itemize}

\bigskip

Si les tests ne permettent pas de conclure, une arête $(u,v)$ du graphe est considérée, et l'algorithme est lancé récursivement sur $G - \{u\}$ et $G - \{v\}$, avec la recherche d'une couverture de taille $k-1$. Si l'un des deux appels récursifs (disons celui sur $G - \{u\}$) renvoie une couverture $\cover$ de taille $k-1$, alors le graphe $G$ contient une couverture de taille $k$, qui s'obtient en ajoutant le sommet $u$ à $\cover$.

Remarque : dans cet algorithme, quand un sommet est supprimé, le graphe garde la même taille $n$ mais ce sommet est noté \og NULL\fg. Donc il faut conserver en mémoire la taille du graphe de départ tout en travaillant sur un sous-graphe induit de taille $n'$ plus réduite.

\vspace{0.35cm}
\begin{algorithm}[H]

\Entree{Un sous-graphe induit $G'$ du graphe $G$, la taille $k$ de la couverture recherchée, la taille $n'$ de $G'$}
\Sortie{Une couverture d'arêtes de taille $k$, sous forme de liste de sommets $cover$}
\BlankLine

\Si{$n' < k$}{
	\Pour{$v \in V(G)$}{
		\Si{$\voisins[v] \neq$ NULL}{
			ajouter $v$ à $\cover$
		}
	}
	\Retour{$\cover$}
}

\Si{$k < 0$}{
	\Retour{NULL}
}

\Si{nombreAretes($G'$) $> k\times(n'-1)$}{
	\Retour{NULL}
}

creation d'un tableau des degres de taille $n$

$u$ = degrePositif($G$,0)

$v$ = voisin de $u$

$g_1$ = copie($G$)

suppressionAretes($g_1$,$u$)

suppressionSommet($g_1$,$u$)

\Si{nombreAretes($g_1$) = 0}{
	ajouter $u$ à $\cover$
	\Retour{$\cover$}
}

$g_2$ = copie($G$)

suppressionAretes($g_2$,$v$)

suppressionSommet($g_2$,$v$)

\Si{nombreAretes($g_2$) = 0}{
	ajouter $v$ à $\cover$
	\Retour{$\cover$}
}

$\mathrm{coverU}$ = petiteCouvertureAlg($g_1$,$k-1$,$n'-1$)

\Si{coverU $\neq$ NULL et taille(coverU) = $k-1$}{
	$\cover$ = $\mathrm{coverU}$
	
	ajouter $u$ à $\cover$
}

\Sinon{
	$\mathrm{coverV}$ = petiteCouvertureAlg($g_2$,$k-1$,$n'-1$)

	\Si{$\mathrm{coverV} \neq$ NULL et taille(coverV) = $k-1$}{
		$\cover$ = $\mathrm{coverV}$
	
		ajouter $v$ à $\cover$
	}
}

\Retour{$\cover$}

\caption{petiteCouvertureAlg - littleCoverAlg}
\end{algorithm}

\subsubsection{Complexité}

Commençons par estimer la complexité de l'algorithme \texttt{littleCoverAlg}. À chaque appel récursif, si la condition d'arrêt n'est pas remplie, l'algorithme va :
\begin{itemize}
 \itemb créer les graphes $g_1$ et $g_2$. La création de ces graphes se fait en parcourant l'ensemble des arêtes, dont la taille est majorée par $k(n-1)$ (condition d'arrêt).
 \itemb s'appeler deux fois lui-même. On obtient ainsi un arbre d'appel d'arité 2.
 \itemb ajouter un sommet à la couverture, la profondeur de l'arbre d'appel est donc majoré par la taille $k$ de la couverture cherchée.
\end{itemize}

Ainsi, l'algorithme \texttt{littleCoverAlg} tournera en $O(2^k k\times n)$. 

\vspace{0.35cm}
Étudions maintenant l'algorithme \texttt{littleCover}. La boucle \texttt{pour} des lignes 6 à 12 demande de déterminer pour chacun des $n$ sommets si son degré est plus grand que $k$ (se fait en $O(k)$). Cette étape de preprocessing ne sera faite qu'une seule fois et sa complexité sera asymptotiquement négligeable. Après cette étape, on appellera \texttt{littleCoverAlg} sur le graphe induit par les sommets restants de degré non nul, si et seulement si ce graphe a moins de $k^2$ arêtes donc moins de $2k^2$ sommets. Comme l'algorithme tourne en $O(2^k k\times n)$, avec $n\leqslant k^2$, l'algorithme final tourne en $O(2^k k^3)$.

\subsubsection{Résultats}

Nous avons testé l'algorithme sur des séries de 100 graphes de 20 sommets, générés aléatoirement avec \texttt{generation} et une probabilité de 0.5.
Nous avons progressivement augmenté la taille $k$ de la couverture à rechercher.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
	\hline 
	k & 9 & 10 & 11 & 12 & 13 & 14  \\
	\hline
	temps & 0 & 0.03 & 0.3 & 1.42 & 5.11 & 10.13  \\
	\hline
\end{tabular}
\end{center}

On voit que le temps d'exécution augmente très vite : le rapport entre le temps d'exécution pour une couverture de taille k et $2^k \times k^3$ est pratiquement constant : il vaut en moyenne $2 \times 10^{-7}$. Cela signifie que les temps d'exécution de l'algorithme \texttt{littleCover} sont en accord avec la complexité estimée.

\section{Résolution avec un sat-solver}

% Proposition de plan qui va sûrement évoluer quand on se sera penchés sur cette partie.

\subsection{Réduction}

Nous nous proposons maintenant de trouver une couverture d'une taille donnée si elle existe, à l'aide du sat-solver Minisat, en passant donc par une réduction du problème vertex cover.

Pour trouver une couverture de taille $p$ à un graphe $G$ donné à $n$ sommets, on crée les variables $(x_{i,k})_{1\leqslant i\leqslant n \atop 1\leqslant k \leqslant p}$ qui indiqueront si le sommet $i$ est le $k^{\text{ième}}$ sommet de la couverture.

Nous avons donc trois contraintes à respecter :
\begin{itemize}
 \itemb Le même sommet $i$ ne peut pas apparaître à deux places $k$ et $l$ différentes dans la couverture.
 \itemb Deux sommets $i$ et $j$ différents ne peuvent pas occuper la même place $k$ dans la couverture
 \itemb Chaque arête doit avoir une extremité dans la couverture.
\end{itemize}

Ces contraintes se formulent en problème de satisfiabilité de la façon suivante 

\[\varphi_1=\dland{i=1} n \quad\dland{1\leqslant k < l \leqslant p}{} (\lnot x_{i,k}) \lor (\lnot x_{i,l})\]

\[\varphi_2=\dland{k=1} p \quad \dland{1\leqslant i < j \leqslant n}{} (\lnot x_{i,k}) \lor (\lnot x_{j,k})\]

\[\varphi_3=\dland{(i,j)\in E(G)}{} \dlor{k=1} p  (\lnot x_{i,k}) \lor (\lnot x_{j,k})\]

Le problème de satisfiabilité auquel se réduit vertex-cover est finalement $\varphi=\varphi_1\land \varphi_2\land \varphi_3$.

\subsection{Algorithme et complexité}

À partir d'un graphe de $n$ sommets, on produit donc :
\begin{itemize}
 \itemb $\frac{np(p-1)}2$ clauses de 2 variables pour $\varphi_1$.
 \itemb $\frac{np(n-1)}2$ clauses de 2 variables pour $\varphi_2$.
 \itemb $|E|$ clauses de $2p$ variables pour $\varphi_3$.
\end{itemize}

On réduit ainsi la recherche d'une $p$-couverture sur $n$ sommets à un problème de $2p$-satisfiabilité à $\frac {np (n+p-2)}2 +|E|$ clauses.

\subsection{Résultats}

\end{document}
